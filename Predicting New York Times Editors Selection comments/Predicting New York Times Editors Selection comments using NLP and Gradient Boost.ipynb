{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting New York Times \"Editor's Selection\" comments using NLP and Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "The following notebook has the goal to predict the \"Editor's Selection\" comments of the open articles from the [New York Times](https://www.nytimes.com/) webpage.\n",
    "\n",
    "The imported dataset contains data from January 2017 until May 2017 and from January 2018 until May 2018, related to articles and comments from NY Times. After importing, some features are pre-selected. The columns are treated and some new features are created. The **editorsSelection** represents if the comment is an \"Editor's Selection\" or not, and is the *target*.\n",
    "\n",
    "The feature **commentBody** represents the comment itself. I separated it and processed the text using **NLP** technique **Bag-of-words**.\n",
    "\n",
    "For the classification, the **Gradient Boosting** Machine Learning algorithm is compared with **SVM** and **Naive Bayes** and tunned with **Grid Search**. Three measures are analyzed: **Accuracy, AUROC, and F1-Score**.\n",
    "\n",
    "Finally, the results are discussed, and some future works are recommended.\n",
    "\n",
    ">Some codes and ideas were inspired by [Aashita Kesarwani Predicting NYT's pick notebook](https://www.kaggle.com/aashita/predicting-nyt-s-pick/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Importing data](#importing)\n",
    "- [Feature Engineering](#feature_engineering)\n",
    "\t- [Treating comments](#fe_comments_treatment)\n",
    "    \t- [Removing tags](#fe_ct_removing_tags)\n",
    "    \t- [Removing wrong encoding](#fe_ct_removing_encoding)\n",
    "    \t- [NER](#fe_ct_ner)\n",
    "    \t- [Removing punctuation](#fe_ct_punctuation)\n",
    "    \t- [Treating English words](#fe_ct_english)\n",
    "\t- [Creating new features](#fe_new_features)\n",
    "    \t- [Quantifying categorical features](#fe_nf_categorical)\n",
    "        - [Normalizing numerical features](#fe_nf_normalizing)\n",
    "\t- [NLP - Bag-of-words](#fe_nlp)\n",
    "    \t- [Count Vectorizer](#fe_nlp_count)\n",
    "    \t- [TF-IDF](#fe_nlp_tf)\n",
    "- [Modeling and evaluating](#model)\n",
    "    - [SVM](#model_svm)\n",
    "    - [Gradient Boost](#model_gradient)\n",
    "    - [Naive Bayes](#model_naive)\n",
    "    - [Grid Search](#model_grid)\n",
    "- [Discussion](#discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data <a name=\"importing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import re, string\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.sparse import hstack\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two kinds of datasets: Articles Dataset and Comments Dataset.\n",
    "\n",
    "The Articles dataset contains more than 9000 articles and 16 features. It represents the articles headers, with information like date of publication (pubDate) and category (newDesk).\n",
    "\n",
    "The Comments dataset contains more than 2 million comments and 34 features. This dataset includes the comment feature (commentBody) and some information about the comment, i.e. comment date of publication (approveDate). Also, it contains the target feature: **editorsSelection**.\n",
    "\n",
    "For now, some features will be *excluded* from our study. Some will be removed due to their nature of non-relation with our problem.\n",
    "\n",
    "Here are the chosen features for now:\n",
    "\n",
    "|\tArticles\t\t|\tComments\t|\n",
    "|---------------------------|---------------------------|\n",
    "|\tarticleID\t\t\t\t|\tarticleID\t\t\t\t|\n",
    "|\tarticleWordCount\t\t|\tcreateDate\t\t\t\t|\n",
    "|\tnewDesk\t\t\t\t\t|\tapproveDate\t\t\t\t|\n",
    "|\ttypeOfMaterial\t\t\t|\tcommentBody\t\t\t\t|\n",
    "|\tpubDate \t\t\t\t|\trecommendations\t\t\t|\n",
    "|\t     -\t\t\t\t\t|\treplyCount\t\t\t\t|\n",
    "|\t\t-\t\t\t\t\t|\teditorsSelection\t\t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_columns = ['articleID', 'articleWordCount', 'newDesk', 'typeOfMaterial', 'pubDate']\n",
    "com_columns = ['articleID', 'createDate', 'approveDate', 'commentBody', 'recommendations', 'replyCount','editorsSelection']\n",
    "\n",
    "df_art_jan17 = pd.read_csv('nyt-comments/ArticlesJan2017.csv', usecols=art_columns)\n",
    "df_com_jan17 = pd.read_csv('nyt-comments/CommentsJan2017.csv', usecols=com_columns)\n",
    "df_art_fev17 = pd.read_csv('nyt-comments/ArticlesFeb2017.csv', usecols=art_columns)\n",
    "df_com_fev17 = pd.read_csv('nyt-comments/CommentsFeb2017.csv', usecols=com_columns)\n",
    "df_art_mar17 = pd.read_csv('nyt-comments/ArticlesMarch2017.csv', usecols=art_columns)\n",
    "df_com_mar17 = pd.read_csv('nyt-comments/CommentsMarch2017.csv', usecols=com_columns)\n",
    "df_art_apr17 = pd.read_csv('nyt-comments/ArticlesApril2017.csv', usecols=art_columns)\n",
    "df_com_apr17 = pd.read_csv('nyt-comments/CommentsApril2017.csv', usecols=com_columns)\n",
    "df_art_may17 = pd.read_csv('nyt-comments/ArticlesMay2017.csv', usecols=art_columns)\n",
    "df_com_may17 = pd.read_csv('nyt-comments/CommentsMay2017.csv', usecols=com_columns)\n",
    "df_art_jan18 = pd.read_csv('nyt-comments/ArticlesJan2018.csv', usecols=art_columns)\n",
    "df_com_jan18 = pd.read_csv('nyt-comments/CommentsJan2018.csv', usecols=com_columns)\n",
    "df_art_fev18 = pd.read_csv('nyt-comments/ArticlesFeb2018.csv', usecols=art_columns)\n",
    "df_com_fev18 = pd.read_csv('nyt-comments/CommentsFeb2018.csv', usecols=com_columns)\n",
    "df_art_mar18 = pd.read_csv('nyt-comments/ArticlesMarch2018.csv', usecols=art_columns)\n",
    "df_com_mar18 = pd.read_csv('nyt-comments/CommentsMarch2018.csv', usecols=com_columns)\n",
    "df_art_apr18 = pd.read_csv('nyt-comments/ArticlesApril2018.csv', usecols=art_columns)\n",
    "df_com_apr18 = pd.read_csv('nyt-comments/CommentsApril2018.csv', usecols=com_columns)\n",
    "\n",
    "comments = [df_com_jan17, df_com_fev17, df_com_mar17, df_com_apr17, df_com_may17, df_com_jan18, df_com_fev18, df_com_mar18, df_com_apr18]\n",
    "df_comments = pd.concat(comments,sort=False)\n",
    "articles = [df_art_jan17, df_art_fev17, df_art_mar17, df_art_apr17, df_art_may17, df_art_jan18, df_art_fev18, df_art_mar18, df_art_apr18]\n",
    "df_articles = pd.concat(articles,sort=False)\n",
    "\n",
    "df = pd.merge(df_articles, df_comments, on='articleID', how='inner',sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering <a name=\"feature_engineering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating comments <a name=\"fe_comments_treatment\"></a>\n",
    "\n",
    "Most of the comments of NY Times naturally are written in English. However, since the comments are opened for anyone, consequently we expect to find errors and unsupported characters (from different languages). For example, HTML tags and Japanese characters.\n",
    "\n",
    "Since the nature of an \"Editor's Selection\" comment is to be well written and containing a relevant opinion about the subject, we must treat the inconveniences of the **commentBody** feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing tags <a name=\"fe_ct_removing_tags\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(text):\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.commentBody = df.commentBody.apply(remove_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing wrong encoding <a name=\"fe_ct_removing_encoding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.65 s, sys: 1.55 s, total: 8.2 s\n",
      "Wall time: 8.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.commentBody = df.commentBody.apply(lambda x: str(x.encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER <a name=\"fe_ct_ner\"></a>\n",
    "\n",
    "Using Name Entity Recognition (NER) and some English dictionary, it is possible to maintain only English words in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Name/Entity/Place dictionary\n",
    "def NER(sr):\n",
    "    continuous_chunk = []\n",
    "    for row in sr:\n",
    "        chunked = ne_chunk(pos_tag(word_tokenize(row)))\n",
    "        prev = None\n",
    "        current_chunk = []\n",
    "        for i in chunked:\n",
    "            if type(i) == Tree:\n",
    "                current_chunk.append(\" \".join([token for token, pos in i.leaves()]))\n",
    "            elif current_chunk:\n",
    "                named_entity = \" \".join(current_chunk)\n",
    "                continuous_chunk.append(named_entity)\n",
    "                current_chunk = []\n",
    "    return set(continuous_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 37s, sys: 4.42 s, total: 22min 41s\n",
      "Wall time: 22min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Using only NER extracted from comments selected as \"Editor's Selection\" to reduce the dictionary\n",
    "people_words = NER(df[df['editorsSelection'] == 1].commentBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating English Dictionary using NLTK package\n",
    "words = set(nltk.corpus.words.words() + list(nltk.corpus.wordnet.words()) + list(people_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuation <a name=\"fe_ct_punctuation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.commentBody = df.commentBody.apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating English words <a name=\"fe_ct_english\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(text) if w in words or w.lower() in words or (nltk.corpus.wordnet.morphy(w.lower()) is not None and nltk.corpus.wordnet.morphy(w.lower()).lower() in words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 47s, sys: 635 ms, total: 3min 47s\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.commentBody = df.commentBody.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new features <a name=\"fe_new_features\"></a>\n",
    "\n",
    "The data features won't be useful in their original conditions. It is necessary to quantify them.\n",
    "\n",
    "In this case, it will be created two new features: **commentApprovalLength**, which represents the waiting time for the comment to be approved; and **commentPubLength**, which is the time between the article publication and the comment publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentApprovalLength'] = df.apply(lambda row: (dt.datetime.fromtimestamp(int(row['approveDate'])) - dt.datetime.fromtimestamp(int(row['createDate']))).total_seconds(), axis=1)\n",
    "df['commentPubLength'] = df.apply(lambda row: (dt.datetime.fromtimestamp(int(row['approveDate'])) - dt.datetime.strptime(row['pubDate'], '%Y-%m-%d %H:%M:%S')).total_seconds(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, it is now possible to count the number of words of the treated commentBody feature creating a new column called **commentWordCount**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['commentWordCount'] = df.apply(lambda row: sum(Counter(row['commentBody'].split()).values()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning unused features\n",
    "df.drop(columns=['approveDate', 'createDate', 'articleID', 'pubDate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantifying categorical features <a name=\"fe_nf_categorical\"></a>\n",
    "\n",
    "The categorical features should be transformed into numerical features to help the classifier to not misinterpret. It will be created new columns to represent the categories in numbers (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"newDesk\", \"typeOfMaterial\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing numerical features <a name=\"fe_nf_normalizing\"></a>\n",
    "\n",
    "The numerical features should be normalized to avoid wrong weighted classification. The MinMaxScaler() will be used for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#Array with numerical features\n",
    "np_numbers = df[['articleWordCount', 'recommendations', 'replyCount', 'commentWordCount', 'commentApprovalLength', 'commentPubLength']].values.astype(float)\n",
    "\n",
    "#Normalizing\n",
    "np_scaled = min_max_scaler.fit_transform(np_numbers)\n",
    "df_normalized = pd.DataFrame(np_scaled)\n",
    "#Renaming columns\n",
    "df_normalized.columns = ['articleWordCount', 'recommendations', 'replyCount', 'commentWordCount', 'commentApprovalLength', 'commentPubLength']\n",
    "\n",
    "#Joining new dataframe\n",
    "cols = [i for i in df.columns.values if i not in list(['articleWordCount', 'recommendations', 'replyCount', 'commentWordCount','commentApprovalLength','commentPubLength'])]\n",
    "df_normalized = df_normalized.join(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>commentWordCount</th>\n",
       "      <th>commentApprovalLength</th>\n",
       "      <th>commentPubLength</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>newDesk_Arts&amp;Leisure</th>\n",
       "      <th>newDesk_Automobiles</th>\n",
       "      <th>...</th>\n",
       "      <th>typeOfMaterial_Editorial</th>\n",
       "      <th>typeOfMaterial_Interview</th>\n",
       "      <th>typeOfMaterial_Letter</th>\n",
       "      <th>typeOfMaterial_News</th>\n",
       "      <th>typeOfMaterial_News Analysis</th>\n",
       "      <th>typeOfMaterial_Obituary (Obit)</th>\n",
       "      <th>typeOfMaterial_Op-Ed</th>\n",
       "      <th>typeOfMaterial_Question</th>\n",
       "      <th>typeOfMaterial_Review</th>\n",
       "      <th>typeOfMaterial_briefing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.160804</td>\n",
       "      <td>0.296117</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>b For all you Americans out there still rejoic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.160804</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>b Obamas policies may prove to be the least of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   articleWordCount  recommendations  replyCount  commentWordCount  \\\n",
       "0          0.080429         0.000477    0.160804          0.296117   \n",
       "1          0.080429         0.000286    0.160804          0.145631   \n",
       "\n",
       "   commentApprovalLength  commentPubLength  \\\n",
       "0               0.001731          0.005408   \n",
       "1               0.002221          0.005402   \n",
       "\n",
       "                                         commentBody  editorsSelection  \\\n",
       "0  b For all you Americans out there still rejoic...                 0   \n",
       "1  b Obamas policies may prove to be the least of...                 0   \n",
       "\n",
       "   newDesk_Arts&Leisure  newDesk_Automobiles           ...             \\\n",
       "0                     0                    0           ...              \n",
       "1                     0                    0           ...              \n",
       "\n",
       "   typeOfMaterial_Editorial  typeOfMaterial_Interview  typeOfMaterial_Letter  \\\n",
       "0                         0                         0                      0   \n",
       "1                         0                         0                      0   \n",
       "\n",
       "   typeOfMaterial_News  typeOfMaterial_News Analysis  \\\n",
       "0                    1                             0   \n",
       "1                    1                             0   \n",
       "\n",
       "   typeOfMaterial_Obituary (Obit)  typeOfMaterial_Op-Ed  \\\n",
       "0                               0                     0   \n",
       "1                               0                     0   \n",
       "\n",
       "   typeOfMaterial_Question  typeOfMaterial_Review  typeOfMaterial_briefing  \n",
       "0                        0                      0                        0  \n",
       "1                        0                      0                        0  \n",
       "\n",
       "[2 rows x 66 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking how the features are now\n",
    "df_normalized.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing classes <a name=\"fe_balancing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the targed feature **editorsSelection** is balanced in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "editorsSelection(1): 1.9107573251608228%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(df_normalized['editorsSelection']).plot.bar(figsize = (5,5))\n",
    "print(\"editorsSelection(1): \" + str((float(pd.value_counts(df_normalized['editorsSelection'])[1])/float(pd.value_counts(df_normalized['editorsSelection']).sum())) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is notable the unbalanced dataset. The editorsSelection class = 1 represents **1.91%** of the entire dataset. To work with this class, it is necessary to downsample the editorsSelection class = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Returns the balanced class using the percentage that is needed to maintain in the class with less occurrence.\n",
    "For example, if we need the class 1 (minority) to represents 30% of the entire dataset, percent = 0.3. \n",
    "The class 0 (majority) will have samples removed randomly until it represents 70% of the entire dataset.\n",
    "'''\n",
    "def downSampling(sample, col_class, percent):\n",
    "    #Finding the majority and minority class\n",
    "    counts = sample[col_class].value_counts().to_dict()\n",
    "    max_label = max(counts.keys(), key=(lambda k: counts[k]))\n",
    "    min_label = min(counts.keys(), key=(lambda k: counts[k]))\n",
    "    #Separating class samples\n",
    "    sample_max = sample[sample[col_class] == max_label]\n",
    "    sample_min = sample[sample[col_class] == min_label]\n",
    "    #Finding the actual ratio between classes\n",
    "    actual_ratio = float(min(counts.values()))/float(sum(counts.values()))\n",
    "    if(actual_ratio >= percent):\n",
    "        return sample\n",
    "    #Calculating the number of necessary samples to be excluded\n",
    "    desired_samples = int(float(min(counts.values()) - (percent * min(counts.values()))) / float(percent))\n",
    "    #Resampling dataset\n",
    "    sample_max_downsampled = resample(sample_max, replace=False, n_samples=desired_samples, random_state=100)\n",
    "    #Combining samples\n",
    "    sample_downsampled = pd.concat([sample_max_downsampled, sample_min])\n",
    "    return sample_downsampled\n",
    "\n",
    "#It was chosen the 1:4 (25%) ratio for downsampling\n",
    "df_normalized_balanced = downSampling(df_normalized, 'editorsSelection', 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "editorsSelection(1): 25.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.value_counts(df_normalized_balanced['editorsSelection']).plot.bar(figsize = (5,5))\n",
    "print(\"editorsSelection(1): \" + str((float(pd.value_counts(df_normalized_balanced['editorsSelection'])[1])/float(pd.value_counts(df_normalized_balanced['editorsSelection']).sum())) * 100)+ \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">It was chosen the value of 25% to compare to [Aashita Kesarwani Predicting NYT's pick notebook](https://www.kaggle.com/aashita/predicting-nyt-s-pick/notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the editorsSelection class = 1 is balanced to represents **25%** of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP - Bag-of-words <a name=\"fe_nlp\"></a>\n",
    "\n",
    "To transform the comments texts in features, the **NLP** technique **Bag-of-words** is implemented in the *commentBody* column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer <a name=\"fe_nlp_count\"></a>\n",
    "\n",
    "The Count Vectorizer transform text into a count vector of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165944, 60959)\n",
      "CPU times: user 9.81 s, sys: 1.01 s, total: 10.8 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_vec = CountVectorizer(stop_words='english', ngram_range=(1,1))\n",
    "counts = count_vec.fit_transform(df_normalized_balanced['commentBody'].values.astype('U'))\n",
    "\n",
    "print(counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF <a name=\"fe_nlp_tf\"></a>\n",
    "To reduce the weight of the counting, it is needed to normalize frequency with TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165944, 60959)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf = tfidf_transformer.fit_transform(counts)\n",
    "\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What we have so far**: cleaned and treated features, extra features and comment texts vectorized.\n",
    "\n",
    "Now we build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and evaluating <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's separate the target feature from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_normalized_balanced[['editorsSelection']]\n",
    "X = df_normalized_balanced.drop(['editorsSelection', 'commentBody'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification algorithm chosen is SVM with linear kernel (**SGDClassifier**).\n",
    "\n",
    "The chosen metrics to measure the model performance will be **Accuracy**, **AUROC**, and **F1-Score**.\n",
    "\n",
    "- Accuracy will measure the overall performance of the model\n",
    "- Area Under ROC Curve (AUROC) checks the model's consistency comparing the true-positive rate against the false-positive rate \n",
    "- F1-Score also validates the unbalanced classes due to the true-positive rate and false-positive rate. It shows how well the model is generalising the predicting.\n",
    "\n",
    "For training and validation, the dataset will be split into three parts: **80%/20%**, **70%/30%** e **60%/40%** (Training/Testing). After that, we calculate the mean of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, predicted):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted, pos_label=1)\n",
    "    roc = auc(fpr, tpr)\n",
    "    f1 = f1_score(y_test, predicted, average='binary')\n",
    "    ac = np.mean(predicted == y_test)\n",
    "    return roc, f1, ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(clf, X_train, y_train, X_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    return predicted\n",
    "\n",
    "def results_train_test(clf, X, y):\n",
    "\n",
    "    X_train_80, X_test_20, y_train_80, y_test_20 = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    X_train_70, X_test_30, y_train_70, y_test_30 = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "    X_train_60, X_test_40, y_train_60, y_test_40 = train_test_split(X, y, stratify=y, test_size=0.4, random_state=42)\n",
    "\n",
    "    pred_20 = train_predict(clf, X_train_80, y_train_80, X_test_20)\n",
    "    pred_30 = train_predict(clf, X_train_70, y_train_70, X_test_30)\n",
    "    pred_40 = train_predict(clf, X_train_60, y_train_60, X_test_40)\n",
    "\n",
    "    roc20, f120, acc20 = get_metrics(y_test_20, pred_20)\n",
    "    roc30, f130, acc30 = get_metrics(y_test_30, pred_30)\n",
    "    roc40, f140, acc40 = get_metrics(y_test_40, pred_40)\n",
    "    mean_roc = (roc20 + roc30 + roc40) / 3\n",
    "    mean_acc = (acc20 + acc30 + acc40) / 3\n",
    "    mean_f1 = (f120 + f130 + f140) / 3\n",
    "    print('Mean Accuracy: {0:0.2f}'.format(mean_acc))\n",
    "    print('Mean AUROC: {0:0.2f}'.format(mean_roc))\n",
    "    print('Mean F1-Score: {0:0.2f}'.format(mean_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the full feature vector, joining the TF-IDF output and the others features.\n",
    "\n",
    ">Hstack is used to avoid memory overflow when adding the TF-IDF features to dataframe. Also, we will work with sparse matrices from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165944, 61023)\n"
     ]
    }
   ],
   "source": [
    "cols = [i for i in df_normalized_balanced.columns.values if i not in list(['editorsSelection','commentBody', 'articleWordCount'])]\n",
    "\n",
    "features_vector = hstack((tfidf,np.array(X['articleWordCount'])[:,None]))\n",
    "for i in cols:\n",
    "    features_vector = hstack((features_vector,np.array(X[i])[:,None]))\n",
    "print(features_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is ready for the supervised learning testing.\n",
    "\n",
    "These three algorithm will be tested:\n",
    "- SGDClassifier (loss = 'hinge' means SVM with Linear Kernel)\n",
    "- XGBoost (Gradient Boost)\n",
    "- MultinomialNB (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM <a name=\"model_svm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating SVM class with arbitrary parameters\n",
    "svm_clf = linear_model.SGDClassifier(loss='hinge', max_iter=20, tol=1e-3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.80\n",
      "Mean AUROC: 0.61\n",
      "Mean F1-Score: 0.35\n",
      "CPU times: user 2.43 s, sys: 252 ms, total: 2.68 s\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_train_test(svm_clf, features_vector, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting <a name=\"model_gradient\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.91\n",
      "Mean AUROC: 0.86\n",
      "Mean F1-Score: 0.81\n",
      "CPU times: user 2min 39s, sys: 553 ms, total: 2min 40s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_train_test(xgb_clf, features_vector, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes <a name=\"model_naive\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = MultinomialNB(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.76\n",
      "Mean AUROC: 0.55\n",
      "Mean F1-Score: 0.23\n",
      "CPU times: user 1.39 s, sys: 353 ms, total: 1.74 s\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_train_test(nb_clf, features_vector, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results, the Gradient boosting **XGBoost** classifier performed better than **SVM** with linear kernel and **Naive Bayes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimise the **XGBoost** performance, **Grid Search** will choose the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search <a name=\"model_grid\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some parameters to grid search\n",
    "cv_params = {\n",
    "    'max_depth': [8, 9, 10], \n",
    "    'min_child_weight': [6, 7, 8],\n",
    "    'learning_rate': [0.1, 0.2]\n",
    "            }\n",
    "#Some default parameters\n",
    "ind_params = {\n",
    "    'nthread': 4,\n",
    "    'n_estimators': 100, \n",
    "    'seed':0, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic'\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the unbalanced dataset is present, using the Grid Search for tunning the *f1-Score* is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(xgb.XGBClassifier(**ind_params),\n",
    "                            cv_params,\n",
    "                             scoring = 'f1', cv = 5, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 33s, sys: 741 ms, total: 3min 33s\n",
      "Wall time: 1h 19min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [8, 9, 10], 'min_child_weight': [6, 7, 8], 'learning_rate': [0.1, 0.2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(features_vector, y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "\tlearning_rate: 0.1\n",
      "\tmax_depth: 8\n",
      "\tmin_child_weight: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\")\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "for param_name in sorted(cv_params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 7, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': 0, 'silent': True, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "best_parameters.update(ind_params)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the best parameters, it is possible to improve XGBoost performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_optm_clf = xgb.XGBClassifier(**best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.91\n",
      "Mean AUROC: 0.87\n",
      "Mean F1-Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "results_train_test(xgb_optm_clf, features_vector, y.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion <a name=\"discussion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost results:\n",
    "\n",
    "|Raw|-\t\t\t|\n",
    "|-|-----------------------|\n",
    "| Mean Accuracy\t\t\t| 0.91 |\n",
    "| Mean AUROC  | 0.86 |\n",
    "| Mean F1-Score\t\t\t| 0.81 |\n",
    "\n",
    "|Grid Search |\t-\t\t\t|\n",
    "|-|-----------------------|\n",
    "| Mean Accuracy| 0.91 |\n",
    "| Mean AUROC  | 0.87 |\n",
    "| Mean F1-Score\t\t\t| 0.82 |\n",
    "\n",
    "The results now are way slightly better after Grid searching some parameters. Improving the f1-score in Grid Search helped the XGBoost to penalize misclassification of the class = 1.\n",
    "\n",
    "When dealing with such unbalanced dataset, the F1-Score is the appropriate measurement to see how the model handles overfitting. The value of 0.82 of F1-Score is good and *acceptable* to use in a production level since the **New York Times** need to look at most comments to make a good choice. If the model is used, it's possible to **reduce** the number of analyzed comments and optimize the editor's work. Also, it can be used to automatize the editor's choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future work suggestions\n",
    "\n",
    "There are some ways to improve the model.\n",
    "\n",
    "- The ignored features from the beginning may be used to achieve new insights into the dataset.\n",
    "- Feature selection may help to improve the model generalisation and avoid overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
